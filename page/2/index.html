<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Seite 2 | Notes</title>
  <meta name="author" content="Yutaro Yamada">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Notes"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/blog/favicon.png" rel="icon">
  <link rel="alternate" href="/blog/atom.xml" title="Notes" type="application/atom+xml">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/blog/">Notes</a></h1>
  <h2><a href="/blog/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/blog/">Home</a></li>
    
      <li><a href="/blog/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-12T14:45:14.000Z"><a href="/blog/2016/08/12/NNprml/">2016-08-12</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/08/12/NNprml/">Neural Network Practice Problem: 5.25</a></h1>
  

    </header>
    <div class="entry">
      
        <p>I decided to do all the practice problems in Chapter 5 of <em>Pattern Recognition and Machine Learning</em> by Bishop. This chapter is about neural nets. Although the material per se is a little bit old, all the fundamentals of neural network are very well explained in here, so even today, when a bunch of new papers on deep neural network come out on arxiv almost everyday, it’s worth reading in my opinion. </p>
<p>So today I did 5.25. The problem reads:</p>
<hr>
<p>Consider a quadratic error function of the form $ E = E_0 + (w - w^{\ast} )^T H (w - w^{\ast}) $, where $w^{\ast}$ represents the minimum, and the Hessian matrix $H$ is positive definite and constant. Suppose the initial weight vector $w^{(0)}$ is chosen to be at the origin and is updated using simple gradient descent<br>$$<br>w^{(\tau)} = w^{(\tau−1)} − \rho \nabla E<br>$$<br>where $\tau$ denotes the step number, and $\rho$ is the learning rate (which is assumed to be small). Show that, after $\tau$ steps, the components of the weight vector parallel to the eigenvectors of $H$ can be written<br>$$<br>w_j^{(\tau)} = (1 − (1 − \rho \lambda_j )^{\tau} ) w_j^{\ast}<br>$$<br>where $w_j = w^Tu_j$ , and $u_j$ and $\lambda_j$ are the eigenvectors and eigenvalues, respectively, of $H$. Show that as $\tau \rightarrow \infty$, this gives $w^{(\tau)} \rightarrow w^*$ as expected, provided $|1 − \rho \lambda_j | &lt; 1$.</p>
<hr>
<p>I’m assuming that since $H$ is a constant, it is evaluated at $w^{\ast}$, and $E_0 = E(w^{\ast})$. </p>
<p>First, since $H$ is a symmetric matrix, we can say that the eigenvalues are all real, and the eigenvectors are orthogonal to each other. </p>
<p>WLOG, we assume the $u_i$s are orthonormal. So the $u_i$s form the orthonormal basis, meaning we can express any vector with these basis vectors. This means that we can express $w - w^{\ast} = \sum_i^n v_i u_i$, where $v_i$s are appropriate coefficients. We can rewrite the equation using matrix form, which is $w - w^{\ast} = U v \iff v = U^T (w - w^{\ast})$, where $U$’s columns are $u_i$s. This expression gives us new perspective: we can view the weight vector $w$ in the original coordinate with a different coordinate, which is obtained by moving $w^{\ast}$ to the origin and rotate the original coordinate by the rotation matrix $U$. </p>
<p>Let’s plug this into the given error function E. We get<br>$$<br>E = E_0 + \frac{1}{2} (Uv)^T H (Uv) = E_0 +\frac{1}{2} v^T U^T H U v<br>$$</p>
<p>Note that $H$ is a symmetric, meaning it is diagonalizable. So we get<br>$$<br>E = E_0 + \frac{1}{2} v^T U^T UDU^T U v<br>$$</p>
<p>Since U is an orthonormal matrix, we have this identity $U^T = U^{-1}$ so everything cancels out, yielding $E = E_0 + \frac{1}{2} v^T D v$. </p>
<p>Note that $E$ is a function of $w$: $E(w)$. What if we look at it from the new coordinate? We see that $E_0(w^{\ast})$ should be 0 because in the new coordinate $w^{\ast}$ is the origin. Then, we have<br>$$<br>E(v) = \frac{1}{2} v^T D v = \frac{1}{2} \sum_i^n \lambda_i v_i^2<br>$$<br>(Note that D is a diagonal matrix with diagonal elements being eigenvalues.)</p>
<p>Then,<br>$$<br>\nabla E_v(v) = D v =  \sum_i^n \lambda_i v_i<br>$$<br>So, the update equation becomes<br>$$<br>v^{(\tau)} = v^{(\tau-1)} - \rho D v^{(\tau-1)} = (I - \rho D) v^{(\tau - 1)}<br>$$</p>
<p>If we look at the last equation coordinate wise, we get $v_i^{(\tau)} =  (1 - \rho \lambda_i) v_i^{(\tau - 1)} $, so by recursion, we get<br>$$<br>v_i^{(\tau)} =  (1 - \rho \lambda_i)^{\tau} v_i^{(0)}<br>$$<br>Now, let’s go back to the original coordinate, and we get<br>$$<br>w_i^{(\tau)} - w_i^{\ast} = (1 - \rho \lambda_i)^{\tau} w_i^{(0)} - w_i^{\ast}<br>$$<br>Since w^{(0)} is the origin, the left term is 0 and moving $w_i^{\ast}$ to left, we get<br>$$<br>w_i^{(\tau)} = (1 - (1 - \rho \lambda_i)^{\tau})w_i^{\ast}<br>$$<br>, which is what we wanted to show. </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-26T22:19:58.000Z"><a href="/blog/2016/07/26/MatrixFactorizationNotes/">2016-07-26</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/07/26/MatrixFactorizationNotes/">Matrix Factorization Notes</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="LU-decomposition"><a href="#LU-decomposition" class="headerlink" title="LU decomposition"></a>LU decomposition</h2><p>Thm 1:<br>N-rank regular matrix A has a unique factorization LU, where L is a N-rank regular matrix and U is a N-rank upper-triangular matrix. </p>
<p>When we think about the signs of eigenvalues in neural network literature, we only deal with Hessian, which is symmetric, so the signs of all eigenvalues uniquely determine the positive definiteness of the Hessian matrix. But this is not generally true for non-symmetric positive definite matrix. </p>
<p>One example of equivalent condition of a matrix being positive definite is the existence of a unique lower triangular matrix L with real and strictly positive diagonal entries s.t. M = LL<em> holds. (M = LL</em> is called Cholesky decomposition.)</p>
<h2 id="Cholesky-decomposition"><a href="#Cholesky-decomposition" class="headerlink" title="Cholesky decomposition"></a>Cholesky decomposition</h2><p>Thm 2:<br>For a symmetric positive definite matrix M, there exists a decomposition s.t. M = LL^T</p>
<p>Pf. (sketch)<br><span>$$M = PDP^T \\
    = PSS^TP^T \\
    = B^TB \quad (B = (PS)^T) \\
    = (QR)^T QR \quad (B = QR) \\
    = R^T Q^{-1} Q R
    = R^T R 
    = LL^T$$</span><!-- Has MathJax --></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-08T01:19:58.000Z"><a href="/blog/2016/07/07/HessianComp/">2016-07-07</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/07/07/HessianComp/">Hessian Computation using TensorFlow</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="Compute-Hessian-using-TensorFlow"><a href="#Compute-Hessian-using-TensorFlow" class="headerlink" title="Compute Hessian using TensorFlow"></a>Compute Hessian using TensorFlow</h1><p>Reference: </p>
<ul>
<li>TensorFlow implementation of K-means algorithm: <a href="https://codesachin.wordpress.com/2015/11/14/k-means-clustering-with-tensorflow/" target="_blank" rel="external">https://codesachin.wordpress.com/2015/11/14/k-means-clustering-with-tensorflow/</a></li>
<li>Calculating Hessian in Theano (application for Newton’s method): <a href="https://groups.google.com/forum/#!topic/theano-users/2c15kq68lp8" target="_blank" rel="external">https://groups.google.com/forum/#!topic/theano-users/2c15kq68lp8</a></li>
</ul>
<p>TensorFlow has a function called tf.gradients() that computes gradient. In the past, I’ve tried to compute Hessian of an neural network objective function in Torch7 using <a href="https://github.com/twitter/torch-autograd" target="_blank" rel="external">torch-autograd</a> but it was somewhat cumbersome; there wasn’t an easy way to store/reshape parameters because Lua uses table for everything. Today, I’d like to do the same thing in TensorFlow. It should be much easier than in Torch7 due to the symbolic differentiation. </p>
<h3 id="Example-1-Quadratic-function"><a href="#Example-1-Quadratic-function" class="headerlink" title="Example 1 : Quadratic function"></a>Example 1 : Quadratic function</h3><p>We are going to use $f(x) = \frac{1}{2} x^T A x + b^T x + c$ as our first example to compute Hessian. When A is a symmetric matrix, the hessian of $f$ should be equal to $A$.</p>
<p>For simplicity, let us start with:<br><span>$$A = \left[
  \begin{array}{rrr}
    2 &amp; 2 &amp; 2 \\
    2 &amp; 2 &amp; 2 \\
    2 &amp; 2 &amp; 2
  \end{array}
\right]
\quad
b = \left[
  \begin{array}{rrr}
    3  \\
    3  \\
    3 
  \end{array}
\right]
\quad
c = 1$$</span><!-- Has MathJax --></p>
<p>The code below calculates the hessian for f(x).  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> math</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHessian</span><span class="params">(dim)</span>:</span></div><div class="line">    <span class="comment"># Each time getHessian is called, we create a new graph so that the default graph (which exists a priori) won't be filled with old ops.</span></div><div class="line">    g = tf.Graph()</div><div class="line">    <span class="keyword">with</span> g.as_default():</div><div class="line">        <span class="comment"># First create placeholders for inputs: A, b, and c.</span></div><div class="line">        A = tf.placeholder(tf.float32, shape=[dim, dim])</div><div class="line">        b = tf.placeholder(tf.float32, shape=[dim, <span class="number">1</span>])</div><div class="line">        c = tf.placeholder(tf.float32, shape=[<span class="number">1</span>])</div><div class="line"></div><div class="line">        <span class="comment"># Define our variable</span></div><div class="line">        x = tf.Variable(np.float32(np.repeat(<span class="number">1</span>,dim).reshape(dim,<span class="number">1</span>)))</div><div class="line"></div><div class="line">        <span class="comment"># Construct the computational graph for quadratic function: f(x) = 1/2 * x^t A x + b^t x + c</span></div><div class="line">        fx = <span class="number">0.5</span> * tf.matmul(tf.matmul(tf.transpose(x), A), x) + tf.matmul(tf.transpose(b), x) + c</div><div class="line">        </div><div class="line">        <span class="comment"># Get gradients of fx with repect to x</span></div><div class="line">        dfx = tf.gradients(fx, x)[<span class="number">0</span>]</div><div class="line">        <span class="comment"># Compute hessian</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(dim):</div><div class="line">            <span class="comment"># Take the i th value of the gradient vector dfx </span></div><div class="line">            <span class="comment"># tf.slice: https://www.tensorflow.org/versions/0.6.0/api_docs/python/array_ops.html#slice</span></div><div class="line">            dfx_i = tf.slice(dfx, begin=[i,<span class="number">0</span>] , size=[<span class="number">1</span>,<span class="number">1</span>])</div><div class="line">            <span class="comment"># Feed it to tf.gradients to compute the second derivative. </span></div><div class="line">            <span class="comment"># Since x is a vector and dfx_i is a scalar, this will return a vector : [d(dfx_i) / dx_i , ... , d(dfx_n) / dx_n]</span></div><div class="line">            ddfx_i = tf.gradients(dfx_i, x)[<span class="number">0</span>] <span class="comment"># whenever we use tf.gradients, make sure you get the actual tensors by putting [0] at the end</span></div><div class="line">            <span class="keyword">if</span> i == <span class="number">0</span>: hess = ddfx_i</div><div class="line">            <span class="keyword">else</span>: hess = tf.concat(<span class="number">1</span>, [hess, ddfx_i]) </div><div class="line">            <span class="comment">## Instead of doing this, you can just append each element to a list, and then do tf.pack(list_object) to get the hessian matrix too.</span></div><div class="line">            <span class="comment">## I'll use this alternative in the second example.  </span></div><div class="line"></div><div class="line">        <span class="comment"># Before we execute the graph, we need to initialize all the variables we defined</span></div><div class="line">        init_op = tf.initialize_all_variables()</div><div class="line">    </div><div class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">            sess.run(init_op)</div><div class="line">            <span class="comment"># We need to feed actual values into the computational graph that we created above. </span></div><div class="line">            feed_dict = &#123;A: np.float32(np.repeat(<span class="number">2</span>,dim*dim).reshape(dim,dim)), b: np.float32(np.repeat(<span class="number">3</span>,dim).reshape(dim,<span class="number">1</span>)) , c: [<span class="number">1</span>]&#125;</div><div class="line">            <span class="comment"># sess.run() executes the graph. Here, "hess" will be calculated with the values in "feed_dict".</span></div><div class="line">            print(sess.run(hess, feed_dict))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">getHessian(<span class="number">3</span>)</div></pre></td></tr></table></figure>
<pre><code>[[ 2.  2.  2.]
 [ 2.  2.  2.]
 [ 2.  2.  2.]]
</code></pre><p>We can see that the result of sess.run(hess, feed_dict) is indeed the desired value: A</p>
<h3 id="Example-2-Multilayer-Perceptron"><a href="#Example-2-Multilayer-Perceptron" class="headerlink" title="Example 2 : Multilayer Perceptron"></a>Example 2 : Multilayer Perceptron</h3><p>Next, we’ll try a small neural network model: Multilayer perceptron. We need to modify our getHessian function a little bit; we need to create one-long vector for parameters, and then slice them according to the model architecture. Otherwise tf.gradients() cannot calculate the hessian matrix.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHessianMLP</span><span class="params">(n_input, n_hidden, n_output)</span>:</span></div><div class="line">    batch_size = <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="comment"># Each time getHessianMLP is called, we create a new graph so that the default graph (which exists a priori) won't be filled with old ops.</span></div><div class="line">    g = tf.Graph()</div><div class="line">    <span class="keyword">with</span> g.as_default():</div><div class="line">        <span class="comment"># First create placeholders for inputs and targets: x_input, y_target</span></div><div class="line">        x_input = tf.placeholder(tf.float32, shape=[batch_size, n_input])</div><div class="line">        y_target = tf.placeholder(tf.float32, shape=[batch_size, n_output])</div><div class="line">    </div><div class="line">        <span class="comment"># Start constructing a computational graph for multilayer perceptron</span></div><div class="line">        <span class="comment">###  Since we want to store parameters as one long vector, we first define our parameters as below and then</span></div><div class="line">        <span class="comment">### reshape it later according to each layer specification.</span></div><div class="line">        parameters = tf.Variable(tf.concat(<span class="number">0</span>, [tf.truncated_normal([n_input * n_hidden, <span class="number">1</span>]), tf.zeros([n_hidden, <span class="number">1</span>]),</div><div class="line">                                                                                                      tf.truncated_normal([n_hidden * n_output,<span class="number">1</span>]), tf.zeros([n_output, <span class="number">1</span>])]))</div><div class="line">        </div><div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"hidden"</span>) <span class="keyword">as</span> scope:</div><div class="line">            idx_from = <span class="number">0</span> </div><div class="line">            weights = tf.reshape(tf.slice(parameters, begin=[idx_from, <span class="number">0</span>], size=[n_input*n_hidden, <span class="number">1</span>]), [n_input, n_hidden])</div><div class="line">            idx_from = idx_from + n_input*n_hidden</div><div class="line">            biases = tf.reshape(tf.slice(parameters, begin=[idx_from, <span class="number">0</span>], size=[n_hidden, <span class="number">1</span>]), [n_hidden]) <span class="comment"># tf.Variable(tf.truncated_normal([n_hidden]))</span></div><div class="line">            hidden = tf.matmul(x_input, weights) + biases</div><div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"linear"</span>) <span class="keyword">as</span> scope:</div><div class="line">            idx_from = idx_from + n_hidden</div><div class="line">            weights = tf.reshape(tf.slice(parameters, begin=[idx_from, <span class="number">0</span>], size=[n_hidden*n_output, <span class="number">1</span>]), [n_hidden, n_output])</div><div class="line">            idx_from = idx_from + n_hidden*n_output</div><div class="line">            biases = tf.reshape(tf.slice(parameters, begin=[idx_from, <span class="number">0</span>], size=[n_output, <span class="number">1</span>]), [n_output]) </div><div class="line">            output = tf.nn.softmax(tf.matmul(hidden, weights) + biases)</div><div class="line">        <span class="comment"># Define cross entropy loss</span></div><div class="line">        loss = -tf.reduce_sum(y_target * tf.log(output))</div><div class="line">        </div><div class="line">        </div><div class="line">        <span class="comment">### Note: We can call tf.trainable_variables to get GraphKeys.TRAINABLE_VARIABLES </span></div><div class="line">        <span class="comment">### because we are using g as our default graph inside the "with" scope. </span></div><div class="line">        <span class="comment"># Get trainable variables</span></div><div class="line">        tvars = tf.trainable_variables()</div><div class="line">        <span class="comment"># Get gradients of loss with repect to parameters</span></div><div class="line">        dloss_dw = tf.gradients(loss, tvars)[<span class="number">0</span>]</div><div class="line">        dim, _ = dloss_dw.get_shape()</div><div class="line">        hess = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(dim):</div><div class="line">            <span class="comment"># tf.slice: https://www.tensorflow.org/versions/0.6.0/api_docs/python/array_ops.html#slice</span></div><div class="line">            dfx_i = tf.slice(dloss_dw, begin=[i,<span class="number">0</span>] , size=[<span class="number">1</span>,<span class="number">1</span>])</div><div class="line">            ddfx_i = tf.gradients(dfx_i, parameters)[<span class="number">0</span>] <span class="comment"># whenever we use tf.gradients, make sure you get the actual tensors by putting [0] at the end</span></div><div class="line">            hess.append(ddfx_i)</div><div class="line">        hess = tf.squeeze(hess) </div><div class="line">        init_op = tf.initialize_all_variables()</div><div class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">            sess.run(init_op)</div><div class="line">            feed_dict = &#123;x_input: np.random.random([batch_size, n_input]), y_target: np.random.random([batch_size, n_output])&#125;</div><div class="line">            <span class="comment">#print(sess.run(loss, feed_dict))</span></div><div class="line">            print(hess.get_shape())</div><div class="line">            print(sess.run(hess, feed_dict))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">getHessianMLP(n_input=<span class="number">3</span>,n_hidden=<span class="number">4</span>,n_output=<span class="number">3</span>)</div></pre></td></tr></table></figure>
<pre><code>(31, 31)
[[  2.19931314e-03  -1.42659002e-03   1.30957202e-03  -8.70158256e-04
    8.50890204e-03  -5.51932165e-03   5.06659178e-03  -3.36654740e-03
    7.25943921e-03  -4.70885402e-03   4.32260381e-03  -2.87219742e-03
    1.87662840e-02  -1.21727986e-02   1.11743081e-02  -7.42488075e-03
   -5.90046346e-02   8.59218910e-02  -2.69172415e-02  -1.75508182e-03
    3.87416431e-03  -2.11908249e-03  -5.98554593e-03   1.32124824e-02
   -7.22693698e-03   3.56099289e-03  -7.86052924e-03   4.29953635e-03
   -1.33406427e-02   2.94481106e-02  -1.61074679e-02]
 [ -1.42659002e-03   2.15499196e-03   2.23391340e-03   5.85207134e-04
   -5.51932165e-03   8.33742879e-03   8.64276756e-03   2.26410269e-03
   -4.70885402e-03   7.11314566e-03   7.37364776e-03   1.93163764e-03
   -1.21727986e-02   1.83881018e-02   1.90615226e-02   4.99345176e-03
   -2.40529864e-03  -1.63234770e-02   1.87287778e-02  -5.11422716e-02
    6.40287027e-02  -1.28864162e-02  -1.72071008e-03  -1.16775408e-02
    1.33982506e-02   1.02370558e-03   6.94734277e-03  -7.97104836e-03
   -3.83513537e-03  -2.60270163e-02   2.98621524e-02] ... [omitted] ]
</code></pre>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-30T10:31:24.000Z"><a href="/blog/2016/06/30/MetricLearningPart1/">2016-06-30</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/06/30/MetricLearningPart1/">Metric Learning Part1</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Metric-Learning-Part-1"><a href="#Metric-Learning-Part-1" class="headerlink" title="Metric Learning: Part 1"></a>Metric Learning: Part 1</h2><hr>
<p><strong><em>Note:</em></strong> <em>this post is the first part of the distance metric series. The first post discusses “Distance Metric Learning, with application<br>to clustering with side-information” (<a href="http://ai.stanford.edu/~ang/papers/nips02-metric.pdf" target="_blank" rel="external">http://ai.stanford.edu/~ang/papers/nips02-metric.pdf</a>) and the<br>second post discusses “Geometric Mean Metric Learning” (<a href="http://suvrit.de/papers/GMML.pdf" target="_blank" rel="external">http://suvrit.de/papers/GMML.pdf</a>)</em></p>
<hr>
<p>I attended one of the optimization session on the first day of ICML and one of the talks I listened to was about geometric<br>mean metric learning (<a href="http://suvrit.de/papers/GMML.pdf" target="_blank" rel="external">http://suvrit.de/papers/GMML.pdf</a>). I was amazed by their result so I’ll make some notes about<br>their method for myself. </p>
<p>In many machine learning tasks (i.e. classification, search, clustering),<br>it is necessary to learn some sort of notion of distance between input<br>data points. For example, in classification, one needs to –</p>
<p>Metric learning was (first?) introduced in this paper: “Distance Metric Learning, with application<br>to clustering with side-information”<br><a href="http://ai.stanford.edu/~ang/papers/nips02-metric.pdf" target="_blank" rel="external">http://ai.stanford.edu/~ang/papers/nips02-metric.pdf</a>.</p>
<h3 id="Problem-Setting"><a href="#Problem-Setting" class="headerlink" title="Problem Setting"></a>Problem Setting</h3><hr>
<p>Suppose we have a set of points <span>$\{x_i\}_{i=1}^n \subseteq R^m$</span><!-- Has MathJax -->. Suppose also we are given a set of “side information” that tells us that a certain set of points are “similar” s.t. <span>$S: (x_i, x_j) \in S \text{ if } x_i \text{ and } x_j \text{ are similar. }$</span><!-- Has MathJax --> How can we encode this similar-dissimilar information in a distance metric? </p>
<h3 id="Simple-answer"><a href="#Simple-answer" class="headerlink" title="Simple answer"></a>Simple answer</h3><hr>
<p>Learn a Mahalanobis distance $d(x,y) = \sqrt{(x-y)^T A (x-y)}$ so that $A$ will somehow encode the desired information. </p>
<p>Now the problem is reduced to how to learn the matrix A. Whenever we want to learn something, we should remind ourselves of viewing it as optimization. To do so, we need to define what we want to minimize (or maximize…just flip the sign of the objective function), which should correspond to the notion of “goodness” of the matrix A. But before that, we will go over how the Mahalanobis distance came in.</p>
<h3 id="Mahalanobis-distance-in-R-2"><a href="#Mahalanobis-distance-in-R-2" class="headerlink" title="Mahalanobis distance in R^2"></a>Mahalanobis distance in R^2</h3><p>To get the feel of it, we will look at some examples. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line">mu = [<span class="number">0</span>, <span class="number">0</span>]</div><div class="line">cov = [[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]]</div><div class="line">x_data, y_data = np.random.multivariate_normal(mu,cov,<span class="number">500</span>).T</div><div class="line"><span class="comment">#x_data = np.float32(np.random.rand(1,1000))</span></div><div class="line"><span class="comment">#y_data = np.float32(np.random.rand(1,1000))</span></div><div class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</div><div class="line">plt.axis([<span class="number">-10.0</span>,<span class="number">10.0</span>,<span class="number">-10.0</span>,<span class="number">10.0</span>],size=<span class="number">20</span>)</div><div class="line">plt.grid(<span class="keyword">True</span>)</div><div class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">plot_out = plt.scatter(x_data,y_data,color=<span class="string">'b'</span>,marker=<span class="string">'o'</span>,label=<span class="string">"$K_2,mu_2$"</span>, alpha=<span class="number">0.3</span>)</div><div class="line">circle = plt.Circle((<span class="number">0</span>,<span class="number">0</span>),<span class="number">1</span>,color=<span class="string">'r'</span>, fill=<span class="keyword">False</span>, alpha=<span class="number">0.9</span>)</div><div class="line">plot_out = ax.add_artist(circle)</div><div class="line"><span class="comment">#plot_out = plt.plot(x_data, y_data, "bo", alpha=0.3, )</span></div><div class="line"></div><div class="line"><span class="comment">#plt.show()</span></div></pre></td></tr></table></figure>
<img src="/blog/2016/06/30/MetricLearningPart1/output_6_0.png" alt="title" title="title">
<p>Suppose that the data distribution were Gaussian and our data samples are distributed according to $N(0, I)$. The red circle marks the unit standard deviation. Now, take two blue points x and y. The Euclidian distance between x and y is $|| x - y ||_2 = \sqrt{(x-y)^T (x-y)}$. Now normally the data are not distributed according to Gaussian, but rather some obscure distribution. In this data distribution, some data samples might be “similar” and others are not. If we use Euclidian distance as a way to measure similarity, we might end up disregarding the intrinsic information within the data distribution. We want to “correct” this.  </p>
<p>To be more concrete, suppose our real data distribution were something like $\mu = 0$ and $Cov = [[1,0], [0, 6]], which is still too simplistic for any real data. Then sample distribution might look like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line">mu = [<span class="number">0</span>, <span class="number">0</span>]</div><div class="line">cov = [[<span class="number">3</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>]]</div><div class="line">x_data, y_data = np.random.multivariate_normal(mu,cov,<span class="number">500</span>).T</div><div class="line"><span class="comment">#x_data = np.float32(np.random.rand(1,1000))</span></div><div class="line"><span class="comment">#y_data = np.float32(np.random.rand(1,1000))</span></div><div class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</div><div class="line">plt.axis([<span class="number">-10.0</span>,<span class="number">10.0</span>,<span class="number">-10.0</span>,<span class="number">10.0</span>],size=<span class="number">20</span>)</div><div class="line">plt.grid(<span class="keyword">True</span>)</div><div class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">plot_out = plt.scatter(x_data,y_data,color=<span class="string">'b'</span>,marker=<span class="string">'o'</span>,label=<span class="string">"$K_2,mu_2$"</span>, alpha=<span class="number">0.3</span>)</div><div class="line">circle = plt.Circle((<span class="number">0</span>,<span class="number">0</span>),<span class="number">1</span>,color=<span class="string">'r'</span>, fill=<span class="keyword">False</span>, alpha=<span class="number">0.9</span>)</div><div class="line">plot_out = ax.add_artist(circle)</div><div class="line"></div><div class="line"><span class="comment"># TO DO: I should fix the red circle so that it will correspond to the blue distribution.</span></div></pre></td></tr></table></figure>
<img src="/blog/2016/06/30/MetricLearningPart1/output_9_0.png" alt="title" title="title">
<p>In order to reflect the distortion, we should use ; what is the correct way to measure the distance between x and y in the new plot? For example, can we say that the point at the top of the distribution and that point right this and this are the same distance? We should fix this because we think that those two points that are along the principle direction should be “more” similar than those that are not (in this case perpendicular). How can we fix this? By rotating back. The rotation matrix we used was C. So one correct distance metric we could use is $|| x - y ||_{C^{-1}} = \sqrt{(x-y)^T C^{-1} (x-y)}$</p>
<p>Now let’s go back to the paper. What the paper says is this: why not let the data decide which matrix $C^{-1}$ to use. </p>
<h3 id="Optimization-problem"><a href="#Optimization-problem" class="headerlink" title="Optimization problem"></a>Optimization problem</h3><p>The simplest formulation would be : <span>$\min \sum_{x_i, y_i \in S} || x_i - y_i ||_A$</span><!-- Has MathJax -->. However, this would lead to the non-interesting answer which is to let A be 0 matrix, which will give us 0 for even pairs of x and y which are in a dissimilar set $D$. So we should have a restriction which prevents that to happen. One way to do is add a constraint on $A$ such that $\sum_{x_i, y_i \in D} || x_i - y_i ||_A \ge c$, where $c$ is some positive constant.  such that (most of) $|| x_i - y_i ||_A = 0$ even if $x_i \neq y_i$, which is not even a distance anymore. (Recall the definition of “distance”.) So the final form is:<br><span>$\min \sum_{x_i, y_i \in S} || x_i - y_i ||_A  \text{ s.t. }  \sum_{x_i, y_i \in D} || x_i - y_i ||_A \ge c \text{ and } A \succeq 0$</span><!-- Has MathJax --></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-06T22:17:33.000Z"><a href="/blog/2016/06/06/Ch19-Approximate-Inference/">2016-06-06</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/06/06/Ch19-Approximate-Inference/">Ch19: Approximate Inference</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Notes for myself: <strong>Ch19</strong> <strong>Approximate Inference</strong> <a href="http://www.deeplearningbook.org/contents/inference.html" target="_blank" rel="external">http://www.deeplearningbook.org/contents/inference.html</a></p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li><p>Inference = compute $P(h|v)$.</p>
</li>
<li><p>There are many situations where you want to calculate the posterior distribution $P(h|v)$ (i.e. sparse coding, ). Here, h is a set of hidden variables and v is a set of observed variables. In general, when the model is complicated, it is intractable to compute the corresponding $P(h|v)$. This chapter introduces many examples of the inference problem, which approximates $P(h|v)$.   </p>
</li>
</ul>
<h3 id="19-1-Inference-as-Optimization"><a href="#19-1-Inference-as-Optimization" class="headerlink" title="19.1 Inference as Optimization"></a>19.1 Inference as Optimization</h3><ul>
<li><p>The core idea of approximate inference.</p>
</li>
<li><p>Given a probabilistic model with latent variables $h$ and observed variables $v$, we want to know how good it is. One measure of goodness is $\log p(v; \theta)$, often called model evidence or marginalized likelihood.</p>
</li>
<li><p>When integrating out $h$ is difficult, we instead seek for an alternative. Is there a way to lower bound $\log p(v, \theta)$?</p>
</li>
<li><p>Consider the following:<br>$$<br>L(v, \theta, q) = \log p(v; \theta) - KL(q(h|v), p(h|v; \theta))<br>$$</p>
</li>
<li><p>Since KL divergence is always non-negative, we can think of L(v, \theta, q) as a lower bound approximation of $\log p(v, \theta)$.  </p>
</li>
<li><p>By modifying the above equation, we have</p>
<span>$$L(v,\theta,q) = \log p(v;\theta) - E_{h \sim q}\log \frac{q(h|v)}{p(h|v;\theta)} \\
= \log p(v; \theta) - E_{h \sim q}\log\frac{q(h|v)}{\frac{p(v,h; \theta)}{p(v; \theta)}} \\
= \log p(v; \theta) - E_{h\sim q}[ \log q(h|v) - \log \frac{p(v,h; \theta)}{p(v; \theta)}] \\
= - E_{h\sim q}[ \log q(h|v) - \log p(v,h; \theta)] \\
= - E_{h\sim q}[ \log q(h|v)] + E_{h \sim q}[\log p(v,h; \theta)] \\
= E_{h \sim q}[\log p(v,h; \theta)] + H(q)$$</span><!-- Has MathJax -->
<p>where <span>$H(q) = - E_{h\sim q}[ \log q(h|v)]$</span><!-- Has MathJax -->.</p>
</li>
<li><p>For an appropriate choice of $q$, $L$ is tractable.</p>
</li>
<li><p>The following sections will show how to derive different forms of approximate inference by using approximate optimization to find $q$.</p>
</li>
</ul>
<h3 id="19-2-Expectation-Minimization"><a href="#19-2-Expectation-Minimization" class="headerlink" title="19.2 Expectation Minimization"></a>19.2 Expectation Minimization</h3><p>(I thought it’s easier to view this section through an example so I’ll add some Mixture-of-Gaussian taste in my notes)</p>
<ul>
<li>The goal is to maximize the lower bound $L(v,\theta, q)$. Note that we have two distinct terms when we expand $L$ in the above section: the left term is parameterized by $\theta$ and the right term is parameterized by $q$.</li>
</ul>
<h3 id="19-3-MAP-Inference-and-Sparse-Coding"><a href="#19-3-MAP-Inference-and-Sparse-Coding" class="headerlink" title="19.3 MAP Inference and Sparse Coding"></a>19.3 MAP Inference and Sparse Coding</h3><p>(will skip this for the time being)</p>
<h3 id="19-4-Variational-Inference-and-learning"><a href="#19-4-Variational-Inference-and-learning" class="headerlink" title="19.4 Variational Inference and learning"></a>19.4 Variational Inference and learning</h3><ul>
<li>The core idea: maximize $L$ over a restricted family of distributions $q$.</li>
</ul>
<h3 id="19-5-Learned-Approximate-Inference"><a href="#19-5-Learned-Approximate-Inference" class="headerlink" title="19.5 Learned Approximate Inference"></a>19.5 Learned Approximate Inference</h3><ul>
<li>The core idea: we can view the iterative optimization of maximizing $L(v,q)$ w.r.t. $q$ as a function $f$ that maps an input $v$ to an approximate distribution $q* = argmax_q L(v,q)$. Once we view this way, we can learn a function $f(v; \theta)$ with neural network.   </li>
</ul>
<h2 id="Ch14-Autoencoders"><a href="#Ch14-Autoencoders" class="headerlink" title="Ch14 : Autoencoders"></a>Ch14 : Autoencoders</h2><h3 id="14-4-Stochastic-Encoders-and-Decoders"><a href="#14-4-Stochastic-Encoders-and-Decoders" class="headerlink" title="14.4 Stochastic Encoders and Decoders"></a>14.4 Stochastic Encoders and Decoders</h3><h2 id="Ch3-Probability-and-Information-Theory"><a href="#Ch3-Probability-and-Information-Theory" class="headerlink" title="Ch3 : Probability and Information Theory"></a>Ch3 : Probability and Information Theory</h2><p><a href="http://www.deeplearningbook.org/contents/prob.html" target="_blank" rel="external">http://www.deeplearningbook.org/contents/prob.html</a></p>
<h3 id="3-13-Information-Theory"><a href="#3-13-Information-Theory" class="headerlink" title="3.13 Information Theory"></a>3.13 Information Theory</h3><p><em>Shannon entropy</em> = $H(x)$ = $-E_{x \sim P}[\log P(x)]$ (also denoted $H(P)$)</p>
<p>In words, the Shannon entropy of a distribution $P$ is the expected amount of information in an event drawn from that distribution.</p>
<p><em>KL divergence</em> = $D<em>{KL}[P || Q]$ = $E</em>{x \sim P}[\log P(x) - \log Q(x)]$</p>
<p><em>Cross entropy</em> = $H(P,Q)$ = $H(P) + D<em>{KL}(P||Q)$ = $-E</em>{x \sim P}\log Q(x)$</p>
<p>Minimizing the cross-entropy w.r.t Q is equivalent to minimizing the KL divergence.</p>
<h2 id="Ch5-Machine-Learning-Basics"><a href="#Ch5-Machine-Learning-Basics" class="headerlink" title="Ch5 : Machine Learning Basics"></a>Ch5 : Machine Learning Basics</h2><h3 id="5-5-Maximum-Likelihood-estimation"><a href="#5-5-Maximum-Likelihood-estimation" class="headerlink" title="5.5 Maximum Likelihood estimation"></a>5.5 Maximum Likelihood estimation</h3><p>-</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-30T06:55:14.000Z"><a href="/blog/2016/05/30/conjugate-gradient/">2016-05-30</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/05/30/conjugate-gradient/">Conjugate Gradient Method Derivation</a></h1>
  

    </header>
    <div class="entry">
      
        <ul>
<li>CG solves a linear equation $Ax = b$.</li>
</ul>
<h4 id="Derivation"><a href="#Derivation" class="headerlink" title="Derivation:"></a>Derivation:</h4><ol>
<li>Recall the step size calculation of Steepest Gradient Descent.</li>
</ol>
<span>$$-\nabla f(x_i)^T r_{i+1} = 0 \\
\iff r_i^T r_{i+1} = 0 \\
\iff (b - Ax_{i+1})^T r_{i} = 0 \\
\iff (b - A(x_i - \alpha \nabla f(x_i))^T r_i = 0 \\
\iff (r_i - \alpha A r_i)^T r_i = 0 \\
\iff \alpha = \frac{r_i^T r_i}{r_i^T A r_i}$$</span><!-- Has MathJax -->
<p>Recall that $f(x) = \frac{1}{2} x^T A x - b^Tx + c$ is the corresponding parabollic function for the linear equation $Ax = b$ (the minus sign for b is just to make it nice when we consider the relation between $Ax=b$ and its quadratic form). And $f’(x) = \frac{1}{2}A^Tx + \frac{1}{2}Ax - b$</p>
<p>When $A$ is symmetric, this becomes $f’(x) = Ax - b$. So $-f’(x_i) = r_i$, where $r_i = b - Ax_i$ (residual vector)</p>
<ol>
<li><p>Recall the typical trajectory of Steepest Descent. It is often redundant or inefficient when it’s close to the true solution. Can we improve somehow? For example, if we can pick $n$ orthogonal search directions {$d_1, d_2, … d_n$} such that we only need exactly one step for each direction to get to the solution, it would be much more efficient. One obvious choice (but impractical) is to choose coordinate axes as our search directions. This would lead us to:</p>
<ul>
<li>Update Equation: $x_{i+1} = x_i + \alpha d_i$</li>
<li>How to find $\alpha$ :<ul>
<li>Observe that $d<em>i$ has to be orthogonal to $e</em>{i+1} = x_{i+1} - x$. So,</li>
</ul>
</li>
</ul>
</li>
</ol>
<span>$$e_{i+1}^T d_i = 0 \\
\iff (x_{i+1} - x)^T d_i = 0 \\
\iff (x_{i} + \alpha d_i - x)^T d_i = 0 \\
\iff (e_{i} + \alpha d_i)^T d_i = 0 \\
\iff \alpha = - \frac{e_{i}^T d_i}{d_i^Td_i}$$</span><!-- Has MathJax -->
<ol>
<li><p>But we don’t know $e_i$ (because we don’t know $x$) so this is useless. But we can modify the above idea by picking an $A$-orthogonal set of search directions, instead of orthogonal one. $d_i$ and $d_j$ is $A$-orthogonal if $d_i^T A d_j = 0$. How can we find an appropriate step size?</p>
</li>
<li><p>Recall the original idea of step size: we want to minimize the function value most by choosing the best step size. It means we want to solve $argmin f(x_i + \alpha d_i)$. Setting the derivative w.r.t. $\alpha$ equal to 0 tells us that</p>
<span>$\frac{\partial{f(x_{i+1})}}{\partial \alpha} = 0 \iff \nabla f(x_{i+1})^T \frac{d}{d \alpha} x_{i+1} = 0 \iff -r_{i+1}^T d_i  = 0 \\$</span><!-- Has MathJax -->
</li>
</ol>
<p>(directional derivative: <a href="http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx" target="_blank" rel="external">http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx</a>)</p>
<p>Now recall that $r_i = b - Ax_i = b - Ax + Ax - Ax_i = -Ae_i$ (Note: b - Ax = 0). So the last term will become<br><span>$$e_{i+1}^T A d_i = 0 \iff (e_i + \alpha d_i)^T A d_i = 0 \\
\iff \alpha = -\frac{e_i^T A d_i}{d_i^T A d_i}
= -\frac{r_i^T d_i}{d_i^T A d_i}$$</span><!-- Has MathJax --></p>
<ul>
<li>So how to find an A-orthogonal set of search directions? Is the existence even guaranteed?</li>
</ul>
<h3 id="Gram-Schmidt-Conjugation"><a href="#Gram-Schmidt-Conjugation" class="headerlink" title="Gram-Schmidt Conjugation"></a>Gram-Schmidt Conjugation</h3><p><a href="https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf" target="_blank" rel="external">https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-28T05:47:17.000Z"><a href="/blog/2016/05/28/duality/">2016-05-28</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/05/28/duality/">Easy way to generate a dual problem</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Consider the following Primal Problem:</p>
<span>$$\min c^T x \quad 
s.t. \quad Ax \ge b, x \ge 0$$</span><!-- Has MathJax -->
<p>Then the Lagrange function will be</p>
<p>$$<br> L(x,p) = c^T x + p^T(b-Ax)<br>$$</p>
<p>If we stare at it for a while, we notice that we can rewrite the primal problem as</p>
<span>$$\min_{x\ge0} \max_{p\ge0} L(x,p)$$</span><!-- Has MathJax -->
<p>(Suppose $b-Ax\ge0$. Then by letting $p$ large, we can make $\max_{p\ge0} L(x,p)$ arbitrarily large. In order to have a sensible solution, we need $b-Ax \le 0$; the constraint is implicitly incorporated by this $max$ operator.)</p>
<p>Flip min and max, and then you get the dual problem:</p>
<span>$$\max_{p\ge0} \min_{x\ge0} L(x,p)$$</span><!-- Has MathJax -->

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-05-21T14:10:25.000Z"><a href="/blog/2016/05/21/History-of-Neural-Nets-Research-since-2006/">2016-05-21</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/05/21/History-of-Neural-Nets-Research-since-2006/">History of Neural Network Research since 2006</a></h1>
  

    </header>
    <div class="entry">
      
        <p>[On-going notes.] </p>
<h2 id="Invention-of-pre-training"><a href="#Invention-of-pre-training" class="headerlink" title="Invention of pre-training"></a>Invention of pre-training</h2><p>2006: Hinton &amp; Salakhutdinov “Reducing the Dimensionality of Data with Neural Networks”</p>
<p>2007: Bengio “Greedy layer-wise training of deep networks”</p>
<p>Pre-training resolved the issue associated with training deep networks.</p>
<p>Glorot, X. and Bengio, Y. “Understanding the difficulty of training deep feedforward neural networks”</p>
<h2 id="2nd-order-method"><a href="#2nd-order-method" class="headerlink" title="2nd order method"></a>2nd order method</h2><p>2010: Martens “Deep Learning via Hessian-Free optimization”</p>
<ul>
<li>showed that HF “is capable of training DNNs from certain random initializations without the use of pre-training, and can achieve lower errors for the various auto-encoding tasks considered (by Hinton &amp; Salakhutdinov” (Hinton 2013))</li>
</ul>
<h2 id="maybe-SGD-wasn’t-that-bad-to-train-deep-nets"><a href="#maybe-SGD-wasn’t-that-bad-to-train-deep-nets" class="headerlink" title="maybe SGD wasn’t that bad to train deep nets?"></a>maybe SGD wasn’t that bad to train deep nets?</h2><ul>
<li>Notably, Chapelle &amp; Erhan (2011) used the random initialization of Glorot &amp; Bengio (2010) and SGD to train the 11-layer autoencoder of Hinton &amp; Salakhutdinov (2006), and were able to surpass the results reported by Hinton &amp; Salakhutdinov (2006). While these results still fall short of those reported in Martens (2010) for the same tasks, they indicate that learning deep networks is not nearly as hard as was previously believed.</li>
</ul>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>2012: Hinton [“Improving neural<br>networks by preventing co-adaptation of feature detectors”]<br>(<a href="http://arxiv.org/abs/1207.0580" target="_blank" rel="external">http://arxiv.org/abs/1207.0580</a>)</p>
<h2 id="learning-rate-schedule-for-momentum"><a href="#learning-rate-schedule-for-momentum" class="headerlink" title="learning rate schedule for momentum"></a>learning rate schedule for momentum</h2><p>2013: Hinton <a href="http://www.cs.toronto.edu/~fritz/absps/momentum.pdf" target="_blank" rel="external">“On the importance of initialization and momentum in deep learning”</a></p>
<ul>
<li>when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization</li>
</ul>
<p>Interesting remark:</p>
<ul>
<li>Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.</li>
</ul>
<p>-&gt; what is the reasoning behind this?</p>
<ul>
<li><p>the optimization problem resembles an estimation one)</p>
</li>
<li><p>One explanation is that previous theoretical analyses and practical benchmarking focused on local convergence in the stochastic setting, which is more of an estimation problem than an optimization one (Bottou &amp; LeCun, 2004). In deep learning problems this final phase of learning is not nearly as long or important as the initial “transient phase” (Darken &amp; Moody, 1993), where a better argument can be made for the beneficial effects of momentum.</p>
</li>
</ul>
<p>what does this estimation-optimization thing mean?</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-01-09T05:00:00.000Z"><a href="/blog/2016/01/09/this-is-amazing/">2016-01-09</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/01/09/this-is-amazing/">This is amazing</a></h1>
  

    </header>
    <div class="entry">
      
        <p>The progress on image generation has been dramatically improved due to VAE/GAN. The quality of Figure 5 in <a href="http://arxiv.org/pdf/1512.09300.pdf" target="_blank" rel="external">this paper</a> is incredible.  </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-01-08T05:00:00.000Z"><a href="/blog/2016/01/08/reading-deep-residual-learning-for-image-recognition/">2016-01-08</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2016/01/08/reading-deep-residual-learning-for-image-recognition/">Reading: Deep Residual Learning for Image Recognition</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Links:</p>
<p><a href="http://tinyclouds.org/colorize/" target="_blank" rel="external">http://tinyclouds.org/colorize/</a></p>
<p>Notes:</p>
<ul>
<li><p>This problem, (gradient vanishing problem) however, has been largely addressed by normalized initialization [23, 9, 37, 13] and intermediate normalization layers [16], which enable networks with tens of layers to start converging for stochastic gradient descent (SGD) with backpropagation [22].  </p>
</li>
<li><p>Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error, as reported in [11, 42] and thoroughly verified by our experiments. Fig. 1 shows a typical example</p>
</li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/blog/" class="alignleft prev">Vorherige Seite</a>
  
  
    <a href="/blog/page/3/" class="alignright next">Nächste Seite</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="q" value="site:runopti.github.io/blog">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/blog/tags/PRML/">PRML</a><small>1</small></li>
  
    <li><a href="/blog/tags/cv/">cv</a><small>1</small></li>
  
    <li><a href="/blog/tags/decision-theory/">decision-theory</a><small>2</small></li>
  
    <li><a href="/blog/tags/math/">math</a><small>7</small></li>
  
    <li><a href="/blog/tags/neuralnet/">neuralnet</a><small>8</small></li>
  
    <li><a href="/blog/tags/optimization/">optimization</a><small>5</small></li>
  
    <li><a href="/blog/tags/paper-memo/">paper-memo</a><small>2</small></li>
  
    <li><a href="/blog/tags/research/">research</a><small>0</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 Yutaro Yamada
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>




<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]],"processEscapes":true}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
