<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Notes</title>
  <meta name="author" content="Yutaro Yamada">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Notes"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/blog/favicon.png" rel="icon">
  <link rel="alternate" href="/blog/atom.xml" title="Notes" type="application/atom+xml">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/blog/">Notes</a></h1>
  <h2><a href="/blog/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/blog/">Home</a></li>
    
      <li><a href="/blog/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-04-16T18:25:49.000Z"><a href="/blog/2017/04/16/model-uncertainty/">2017-04-16</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/04/16/model-uncertainty/">model uncertainty implementation notes</a></h1>
  

    </header>
    <div class="entry">
      
        <ul>
<li>Model uncertainty can be obtained from dropout NN models. </li>
</ul>
<p>Our approximate predictive distirbution is<br><span>$$q(y^* | x^*) = \int p(y^*| x^*, w) q(w) dw$$</span><!-- Has MathJax --><br>where  <span>$w = \{ W_i \}_{i=1}^L$</span><!-- Has MathJax --> is the set of random variables for a model with $L$ layers. </p>
<p>Sample $T$ sets of Bernoulli distributed random vectors, which gives us <span>$\{ W_1^t,...,W_L^t \}_{t=1}^T$</span><!-- Has MathJax -->. Then<br><span>$$E_{q(y^*|x^*)} (y^*) \approx \frac{1}{T} \sum_{t=1}^T \hat{y}^*(x^*, W_1^t,...,W_L^t)$$</span><!-- Has MathJax --> </p>
<p>This is equivalent to performing $T$ stochastic forward passes through the network and averaging the results. </p>
<p>As for variance,</p>
<p>This is equivelent to the sample variance of $T$ stochastic forward passes through the NN plus the inverse model precision. </p>
<p>Model precision can be found by the following identity:<br><span>$$\tau = \frac{p l^2}{2 N \lambda}$$</span><!-- Has MathJax --> </p>
<p>We can estimate our predictive log-likelihood by Monte Carlo integration of the predictive probability of $y$, which is an estimate of how well the model fits the mean and uncertainty. </p>
<p>For regression, this is given by<br><span>$$\log p(y^*|x^*, X, Y) \approx logsumexp \left ( - \frac{1}{2} \tau ||y-\hat{y}||^2$$</span><!-- Has MathJax --> </p>
<h3 id="Procedure"><a href="#Procedure" class="headerlink" title="Procedure"></a>Procedure</h3><p>Given point $x$:</p>
<ul>
<li>Drop units at test time </li>
<li>Repeat $T$ times</li>
<li>Look at mean and sample variance </li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-26T01:34:41.000Z"><a href="/blog/2017/03/25/rkhs-intuition/">2017-03-25</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/25/rkhs-intuition/">RKHS Intuition</a></h1>
  

    </header>
    <div class="entry">
      
        <p>At first RKHS looked scary, but after I realized that it’s just a space where every point in the space is a linear combination of (positive-definite) kernels, which allows us to replace the inner product calculation in this space with the kernel evaluation, I feel like things are much simpler now. </p>
<p>After all, the following two facts lead to the reproducing property (which can be verified by simple algebra):</p>
<ul>
<li><p>the RKHS is spanned by kernels</p>
</li>
<li><p>the “regular” inner product definition </p>
</li>
</ul>
<p>Often times, the reproducing property is introduced to define RKHS (because it’s simpler?), but at least to me, viewing the reproducing property as a natural consequence from these two facts above was easier to grasp the concept of RKHS than thinking it as a condition required to construct RKHS, although this is more like the chicken and egg thing. </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-17T21:31:33.000Z"><a href="/blog/2017/03/17/risk-bounds/">2017-03-17</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/17/risk-bounds/">On Cross Validation</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Setting"><a href="#Setting" class="headerlink" title="Setting"></a>Setting</h2><ul>
<li>We have models $\mathcal{M}_1, …, \mathcal{M}_k$. </li>
<li>There are $2n$ data points</li>
<li>Split the data randomly into two: $D = (Y_1, …, Y_n)$ and $T = (Y^<em>_1,…,Y^</em>_n)$. </li>
</ul>
<h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition 1"></a>Definition 1</h3><p>A random variable $X$ with mean $\mu = E[X]$ is sub-Gaussian if there is a positive number $\sigma$ such that </p>
<span>$$E[e^{\lambda (X - \mu)}] \le e^{\frac{\sigma^2 \lambda^2}{2}}$$</span><!-- Has MathJax -->
<h3 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1:"></a>Step 1:</h3><ul>
<li>Find MLE $\hat{\theta}_j$ using $D$. </li>
</ul>
<p>(WIP)</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>AIC,BIC,Cross-Validation:  </p>
<ul>
<li><a href="http://www.stat.cmu.edu/~larry/=stat705/Lecture16.pdf" target="_blank" rel="external">http://www.stat.cmu.edu/~larry/=stat705/Lecture16.pdf</a></li>
</ul>
<p>Concentration inequalities: </p>
<ul>
<li><a href="https://www.stat.berkeley.edu/~mjwain/stat210b/Chap2_TailBounds_Jan22_2015.pdf" target="_blank" rel="external">https://www.stat.berkeley.edu/~mjwain/stat210b/Chap2_TailBounds_Jan22_2015.pdf</a></li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-16T15:27:50.000Z"><a href="/blog/2017/03/16/dropout-bayesian/">2017-03-16</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/16/dropout-bayesian/">Supplementary Notes for  Dropout as a Bayesian Approximation</a></h1>
  

    </header>
    <div class="entry">
      
        <p>(notes to myself)</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>The dropout objective minimises the KL divergence between an approximate distribution and the posterior of a deep Gaussian process (marginalized over its finite rank covariance function parameters). </p>
<h2 id="Gaussian-Processes"><a href="#Gaussian-Processes" class="headerlink" title="Gaussian Processes"></a>Gaussian Processes</h2><ul>
<li>models distributions over functions. </li>
<li>offers a way to get uncertainty estimates over the function values, robustness to over-fitting, and principled ways of hyper-parameter tuning. </li>
</ul>
<h4 id="How-to-get-uncertainty-information-from-these-deep-learning-models-for-free-–-without-changing-a-thing"><a href="#How-to-get-uncertainty-information-from-these-deep-learning-models-for-free-–-without-changing-a-thing" class="headerlink" title="How to get uncertainty information from these deep learning models for free – without changing a thing"></a>How to get uncertainty information from these deep learning models for free – without changing a thing</h4><ul>
<li>it’s long been known that these deep tools can be related to Gaussian processes</li>
<li><p>What are the uncertainty estimates that we can get from Gaussian proceses?<br>– Variance of a predictive distribution. </p>
</li>
<li><p>So when we say, we can get uncertainty information from dropout network, it means that we can just calculate the variance of the predictive distribution induced by our dropout network. </p>
</li>
</ul>
<h4 id="How-exactly-do-we-calculate-the-variance-of-the-predictive-distribution"><a href="#How-exactly-do-we-calculate-the-variance-of-the-predictive-distribution" class="headerlink" title="How exactly do we calculate the variance of the predictive distribution?"></a>How exactly do we calculate the variance of the predictive distribution?</h4><ul>
<li><ol>
<li>Define a prior length-scale $l$, which captures our belief over the function frequency. A short length-scale ll corresponds to high frequency data, and a long length-scale corresponds to low frequency data.</li>
</ol>
</li>
<li><ol>
<li>Take the length-scale squared, and divide it by the weight decay. We then scale the result by half the dropout probability over the number of data points. That is,</li>
</ol>
</li>
</ul>
<span>$$\tau = \frac{l^2 p}{2 N \lambda}$$</span><!-- Has MathJax --> 
<p>where $p$ indicates the probability of the units not being dropped. (usually $p$ is the probability of units being dropped, so be careful!)</p>
<ul>
<li><ol>
<li>This $\tau$ is the Gaussian Process precision. (to see why see the derivation part.)</li>
</ol>
</li>
<li><ol>
<li>Next, simulate a network with a test point $x^<em>$ with dropout on. Repeat this $T$ times with different units dropped, and collect the results ${ y</em><em>t }</em>{t=1}^T$. These are empirical samples from our approximate predictive posterior distribution. </li>
</ol>
</li>
<li><ol>
<li>We can get an empirical estimator for the predictive mean of our approximate posterior as well as the predictive variance (our uncertainty) from these samples as follows:</li>
</ol>
</li>
</ul>
<span>$$E[ y^*] \approx \frac{1}{T} \sum_{t=1}^T \hat{y}^*_t(x^*) \\ 
Var[y^*] \approx \tau^{-1} I + \frac{1}{T} \sum_{t=1}^T \hat{y}^*_t (x^*)^T \hat{y}^*_t (x^*) - E[y^*]^T E[y^*]$$</span><!-- Has MathJax --> 
<h3 id="Bayesian-approach-to-function-approximation"><a href="#Bayesian-approach-to-function-approximation" class="headerlink" title="Bayesian approach to function approximation"></a>Bayesian approach to function approximation</h3><p>Given a training set <span>$\{ X_i, Y_i \}_{i=1}^n$</span><!-- Has MathJax -->, we want to estimate a function $y = f(x)$ that is likely to describe the relationship between $X$ and $Y$. </p>
<p>Following the Bayesian approach, we can put some prior distribution over the space of functions $p(f)$.<br>We then look for the posterior distribution given data $(X,Y)$:</p>
<span>$$p(f|X,Y) \propto p(Y|X, f) p(f)$$</span><!-- Has MathJax --> 
<p>This distribution captures the most likely functions given $(X,Y)$.<br>A prediction can be done in the following way:</p>
<span>$$p(y^*|x^*, X,Y) = \int p(y^*|x^*,f) p(f|X,Y) df \\
\iff p(y^*|x^*, X,Y) = \int p(y^*|f) p(f|x,X,Y) df$$</span><!-- Has MathJax -->
<p>Covariance function is like a kernel function: it takes two arguments, and returns a similarity of these two.  Therefore, given some $n by p$ data matrix, this function induces an $n \times n$ covariance matrix. </p>
<h2 id="How-do-these-functions-correspond-to-the-Gaussian-process"><a href="#How-do-these-functions-correspond-to-the-Gaussian-process" class="headerlink" title="How do these functions correspond to the Gaussian process?"></a>How do these functions correspond to the Gaussian process?</h2><h2 id="Why-can-we-think-that-the-noise-as-approximate-integration"><a href="#Why-can-we-think-that-the-noise-as-approximate-integration" class="headerlink" title="Why can we think that the noise as approximate integration?"></a>Why can we think that the noise as approximate integration?</h2><ul>
<li>Because averaging forward passes through the network is equivalent to Monte Carlo integration over a Gaussian process posterior approximation.</li>
</ul>
<h3 id="Derivation"><a href="#Derivation" class="headerlink" title="Derivation"></a>Derivation</h3><ul>
<li>averaging forward passes: </li>
</ul>
<span>$$p(y^* | x^*, X, Y) = \int p(y^*|x^*,\omega) p(\omega|X,Y) d\omega$$</span><!-- Has MathJax --> 
<p>where one forward pass calculation (given all the weights $\omega$ and the test input <span>$x^*$</span><!-- Has MathJax -->) is equal to one sample draw from this distribution <span>$p(y^*|x^*,\omega)$</span><!-- Has MathJax -->, where we define </p>
<span>$$p(y^*|x^*,\omega) = N(y^*; \sqrt{\frac{1}{K}} \sigma(x^* W_1 + b) W_2, \tau^{-1} I_n)$$</span><!-- Has MathJax --> 
<h1 id="Gaussian-Process"><a href="#Gaussian-Process" class="headerlink" title="Gaussian Process"></a>Gaussian Process</h1><ul>
<li><p>A Gaussian process is completely specified by its mean function and covariance function. </p>
</li>
<li><p>The predictions from a GP model take the form of a full predictive distribution</p>
</li>
<li><p>A Gaussian process is a collection of random variables, any finite number of which have a joint Gaussian distribution. </p>
</li>
<li><p>The random variables represent the value of the function $f(x)$ at location $x$. </p>
</li>
<li><p>Often, GP is defined over time, where the index set of random variables is time, but this is not normally the case. </p>
</li>
<li><p>Usually, the index set $\mathcal{X}$ is the set of all possible inputs, i.e. $\mathbb{R}^D$. </p>
</li>
</ul>
<p>Question: When you say “distribution over functions”, it means we put some probability mass on every possible function in the function space of interest. How do we put such a mass in what way? </p>
<p>-&gt; We can see this from the fact that we can draw samples from the distribution of functions evaluated at any number of points; i.e. we choose a number of input points $X_*$ and write out the corresponding covariance matrix using pre-defined covariance function elementwise. Then we generate a random Gaussian vector with this covariance matrix:</p>
<span>$$f_* \sim N(0, K(X_*, X_*))$$</span><!-- Has MathJax -->
<p>(WIP)</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p>Yarin Gal’s blog post about the paper</p>
<ul>
<li><a href="http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html" target="_blank" rel="external">http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html</a></li>
</ul>
<p>The paper :<br>“Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning”</p>
<ul>
<li><a href="https://arxiv.org/abs/1506.02142" target="_blank" rel="external">https://arxiv.org/abs/1506.02142</a></li>
<li><a href="https://arxiv.org/pdf/1506.02157.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1506.02157.pdf</a></li>
</ul>
<p>Textbook: Gaussian Processes for Machine Learning</p>
<ul>
<li><a href="http://www.gaussianprocess.org/gpml/chapters/RW2.pdf" target="_blank" rel="external">http://www.gaussianprocess.org/gpml/chapters/RW2.pdf</a></li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-15T18:11:49.000Z"><a href="/blog/2017/03/15/pathwise/">2017-03-15</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/15/pathwise/">Pathwise Estimator</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Assumption"><a href="#Assumption" class="headerlink" title="Assumption"></a>Assumption</h2><ul>
<li>$z = t(\epsilon, v)$ for $\epsilon \sim s(\epsilon)$ implies $z \sim q(z; v)$. </li>
</ul>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><span>$$\epsilon \sim N(0,1) \\
z = t(\epsilon, v) \text{,  where  } t(\epsilon,v) = \epsilon v_1 + v_0 \\
\Rightarrow z \sim q(z; v) \text{,  where  } q(z; v) =  N(v_0, v_1^2)$$</span><!-- Has MathJax --> 
<p>That is, the distribution of $Z$: $q(z)$ is parameterized by $v = [v_0, v_1^2] = [\mu, \sigma^2]$.</p>
<ul>
<li>$\log p(x,z)$ and $\log q(z; v)$ are differentiable with respect to $z$. </li>
</ul>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>Recall that EBLO is the following:</p>
<span>$$L(v) = E_{q(z;v)}[\log p(x,z) - \log q(z;v)]$$</span><!-- Has MathJax -->
<p>If we define $g(z,v) = \log p(x,z) - \log q(z;v)$, then we can express $\nabla_v L(v)$ as:</p>
<span>$$\nabla_v L(v) = \nabla_v \int g(z,v) q(z; v) dz \\
= \int \nabla_v q(z; v) g(z,v) + q(z; v) \nabla_v g(z,v) dz \\
= \int q(z;v) \nabla_v \log q(z;v) g(z,v) + q(z;v) \nabla_v g(z,v) dz \\
= E_{q(z;v)} \left [ \nabla_v \log q(z;v) g(z,v) + \nabla_v g(z,v) \right ]$$</span><!-- Has MathJax --> 
<p>We can rewrite the above gradient using $z = t(\epsilon, v)$:</p>
<span>$$\nabla_v L(v) =  \int [\nabla_v \log q(z;v) g(z,v) + \nabla_v g(z,v)] q(z;v) dz \\
= E_{s(\epsilon)} \left [ \nabla_v \log s(\epsilon) g(t(\epsilon, v),v) + \nabla_v g(t(\epsilon, v),v) \right ]$$</span><!-- Has MathJax -->
<p>Since $\log s(\epsilon)$ doesn’t depend on $v$, the first term will disappear. Then,</p>
<span>$$\nabla_v L(v) = E_{s(\epsilon)} [\nabla_v g(t(\epsilon, v),v)] \\
= E_{s(\epsilon)} [ \nabla_v (\log p(x,z) - \log q(z;v)) ] \\
= E_{s(\epsilon)} [ \frac{1}{p(x,z)} \log \nabla_v p(x,z) -  \frac{1}{q(z;v)} \log \nabla_v q(z;v)) ] \\
= E_{s(\epsilon)} [ \frac{1}{p(x,z)} \log \nabla_z p(x,z) \frac{\partial z}{\partial v} - \frac{1}{q(z;v)} \log \nabla_v q(z;v)) ] \\$$</span><!-- Has MathJax --> 
<span>$$\nabla_v L(v) = E_{s(\epsilon)} [\nabla_v g(t(\epsilon, v),v)] \\
= E_{s(\epsilon)} [ \nabla_v (\log p(x,z) - \log q(z;v)) ] \\
= E_{s(\epsilon)} [ \nabla_z (\log p(x,z) -  \frac{1}{q(z;v)) \nabla_v t(\epsilon, v) - \nabla_v \log q(z; v) ]  \\
= E_{s(\epsilon)} [ \frac{1}{p(x,z)} \log \nabla_z p(x,z) \frac{\partial z}{\partial v} - \frac{1}{q(z;v)} \log \nabla_v q(z;v)) ] \\$$</span><!-- Has MathJax -->
<p>(WIP)</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>Variational Inferene NIPS Tutorial:</p>
<ul>
<li><a href="http://www.cs.columbia.edu/~blei/talks/2016_NIPS_VI_tutorial.pdf" target="_blank" rel="external">http://www.cs.columbia.edu/~blei/talks/2016_NIPS_VI_tutorial.pdf</a></li>
</ul>
<p>Blog post about MONTE CARLO GRADIENT ESTIMATORS</p>
<ul>
<li><a href="http://andymiller.github.io/2016/12/19/elbo-gradient-estimators.html#fn:2" target="_blank" rel="external">http://andymiller.github.io/2016/12/19/elbo-gradient-estimators.html#fn:2</a></li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-15T16:06:06.000Z"><a href="/blog/2017/03/15/alternative-blockwise/">2017-03-15</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/15/alternative-blockwise/">Nonparametric Regression 03</a></h1>
  

    </header>
    <div class="entry">
      
        <p>In this post, we will modify the blockwise estimation procedure we discussed last time, to reduce the constant factor appeared in our upper bound on the expected risk. </p>
<h2 id="Alternative-Blockwise-Estimator"><a href="#Alternative-Blockwise-Estimator" class="headerlink" title="Alternative Blockwise Estimator"></a>Alternative Blockwise Estimator</h2><p>The issue is that the number of blocks could be very small compared to the number of observations. For example, when $n=1024$, the number of blocks $K = 10$. </p>
<p>Previously, we set each block size to be the power of 2. That is, $|B_k| = 2^k$. </p>
<p>To have a smaller blocksize, we can set $|B_k| = \lfloor (1+a)^k \rfloor$, where $0 &lt; a &lt; 1$. </p>
<p>In fact, if we set $a = \log_2 n$, we see that:</p>
<span>$$n = \sum_{k=1}^K (1 + \frac{1}{\log_2 n} )^k =$$</span><!-- Has MathJax --> 
<p>(WIP)</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-13T16:20:10.000Z"><a href="/blog/2017/03/13/adaptive-pinsker/">2017-03-13</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/13/adaptive-pinsker/">Nonparametric Regression 02</a></h1>
  

    </header>
    <div class="entry">
      
        <p>In the last post, we investigated a Gaussian Sequence model and showed minimax rate:</p>
<span>$$\inf_{\hat{\theta}} \sup_{\Theta} E || \hat{\theta} - \theta ||^2 \asymp M^{\frac{1}{2\alpha + 1}} n^{-\frac{2\alpha}{2\alpha+1}}$$</span><!-- Has MathJax --> 
<p>The crucial assumption to derive this bound is that we assumed $\alpha$ and $M$ are known, which defines a Sobolev ellipsoid, our parameter space. </p>
<p>In this post, we remove that assumption and attempt to achieve the same risk bound (up to some constant).</p>
<p>To recap, the followings are our model description and parameter space.</p>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><span>$$Y_i = \theta_i + \frac{1}{\sqrt{n}} \sigma Z_i, \text{ where } Z_i \sim^{iid} N(0,1)$$</span><!-- Has MathJax --> 
<h3 id="Parameter-space"><a href="#Parameter-space" class="headerlink" title="Parameter space"></a>Parameter space</h3><span>$$\Theta = \{ \theta : \sum_{i=1}^{\infty} i^{2 \alpha} \theta^2_i \le M \}$$</span><!-- Has MathJax -->
<h2 id="Adaptive-Estimation"><a href="#Adaptive-Estimation" class="headerlink" title="Adaptive Estimation"></a>Adaptive Estimation</h2><p>Recall that the naive estimation procedure in the previous post just uses an observation as our estimator for small $i$s and 0 for large $i$s.<br>It worked because we were able to optimize $I$ based on $\alpha$ and $M$.<br>Now since we don’t have access to $\alpha$ and $M$, we have to take an alternative estimation procedure.<br>Since the only available information we have is data, we want our procedure to reflect this information in a meaningful way.  </p>
<p>To get a hint, we will look into how James-Stein estimator was conceived.</p>
<h3 id="James-Stein-Estimator"><a href="#James-Stein-Estimator" class="headerlink" title="James-Stein Estimator"></a>James-Stein Estimator</h3><p>James-Stein estimator is a form of $\delta(X) = a^T X$ (linear procedure) where $a$ is a data-dependent parameter.<br>(That is, JS estimator is adaptive to the $|| \theta ||^2$.) </p>
<p>If we have $m$ observations such that</p>
<span>$$X_i = \theta_i + \sigma Z_i , Z_i \sim^{i.i.d} N(0,1)$$</span><!-- Has MathJax --> 
<p>Then JS estimator is</p>
<span>$$\hat{\theta}_{JS} = (1 - \frac{(m-2)\sigma^2}{\sum_{i=1}^m X_i^2} ) X$$</span><!-- Has MathJax --> 
<p>where $X$ represents a $m$ dimensional vector (so we put all the $m$ observations into one vector). </p>
<p>We say that JS-estimator is mimicking linear estimator because the difference of the two risks is bounded by some constant:</p>
<span>$$E || \hat{\theta}_{JS} - \theta ||^2 - \inf_c E || c X - \theta ||^2 \le \text{constant}$$</span><!-- Has MathJax --> 
<p>To see this, we will investigate each term and show the difference is bounded.<br>(assume $\sigma=1$ without loss of generality.) </p>
<h3 id="The-First-Term"><a href="#The-First-Term" class="headerlink" title="The First Term"></a>The First Term</h3><span>$$E || \hat{\theta}_{JS} - \theta ||^2 =  E_{X|\theta} \sum_{i=1}^m (X_i - \frac{m-2}{||X||^2} - \theta_i)^2  \\
= E_{X|\theta} \sum_{i=1}^m ((X_i - \theta)^2 + \frac{(m-2)^2}{(||X||^2)^2} X_i^2 - 2(X_i - \theta_i) \frac{m-2}{||X||^2} X_i  ) \\
= m + E_{X|\theta} (\frac{(m-2)^2}{||X||^2} ) - 2 \sum_{i=1}^m E_{X|\theta} (X_i - \theta) \frac{m-2}{||X||^2} X_i$$</span><!-- Has MathJax -->
<p>To go further, we will need Stein’s identity (simplified version):</p>
<span>$$\text{For } Y \sim N(\theta, 1), \text{ we have } 
E_{Y|\theta} (Y - \theta) g(Y) = E_{Y|\theta} g&apos;(Y)$$</span><!-- Has MathJax --> 
<p>under some regularity assumption for $g$. </p>
<p>In our case, $Y=X_i$ and  $g(X_i) = \frac{m-2}{||X||^2} X_i$.</p>
<p>By the above identity, we have</p>
<span>$$\sum_{i=1}^m E_{X|\theta} (X_i - \theta) \frac{m-2}{||X||^2} X_i
= \sum_{i=1}^m E_{X|\theta} \frac{\partial}{\partial X_i}(\frac{m-2}{||X||^2}X_i) \\
= \sum_{i=1}^m E_{X|\theta}( \frac{m-2}{||X||^2} + \frac{-(m-2) 2X_i}{(\sum_{i=1}^m X_i^2)^2}X_i ) \\
= E_{X|\theta} (\frac{m(m-2)}{||X||^2} - \frac{2 (m-2)}{||X||^2} ) \\
= E_{X|\theta} (\frac{m(m-2)^2}{||X||^2}  ) \\$$</span><!-- Has MathJax --> 
<p>This gives us</p>
<span>$$E || \hat{\theta}_{JS} - \theta ||^2 =  m + E_{X|\theta} (\frac{(m-2)^2}{||X||^2} ) - 2 \sum_{i=1}^m E_{X|\theta} (X_i - \theta) \frac{m-2}{||X||^2} X_i \\
= m - E_{X|\theta} \frac{(m-2)^2}{||X||^2}$$</span><!-- Has MathJax --> 
<p>Now to get an upper bound on this, we will apply Jensen’s inequality but before that we will use the following property of noncentral Chi-squared distribution to simplify (noncentral because each $X_i$ has a different mean $\theta_i$):</p>
<span>$$||X||^2 = \sum_{i=1}^m X_i^2 \sim \chi_{m+2N},&nbsp;\text{ where } N \sim Poisson \left(\frac{||\theta||^2}{2} \right)$$</span><!-- Has MathJax --> 
<p>By conditioning on $N$, we have</p>
<span>$$m - E_{X|\theta} \frac{(m-2)^2}{||X||^2} = m - E_N \left[ E_{X|N} \frac{(m-2)^2}{||X||^2} | N \right]  \\
= m - E_N \frac{(m-2)^2}{m+2N-2}  \text{  (Note that } E\frac{1}{\chi^2_d} = \frac{1}{d-2} \text{)} \\
\le m - \frac{(m-2)^2}{m-2 + 2E_N[n]} \text{  Note (Jensen&apos;s inequality):} E \frac{1}{Y} \ge \frac{1}{EY} \\
= m - \frac{(m-2)^2}{m-2 + ||\theta||^2} \\
= 2 + m - 2 - \frac{(m-2)^2}{m-2 + ||\theta||^2} \\
= 2 + \frac{(m-2)||\theta||^2}{m-2 + ||\theta||^2} \\
\le 2 + \frac{m||\theta||^2}{m + ||\theta||^2}$$</span><!-- Has MathJax -->
<p>When $\sigma \neq 1$, it’s going to be </p>
<span>$$E ||\hat{\theta} - \theta||^2  \le 2\sigma^2 + \frac{m \sigma^2 ||\theta||^2}{m\sigma^2 + ||\theta||^2}$$</span><!-- Has MathJax -->
<h3 id="The-Second-Term"><a href="#The-Second-Term" class="headerlink" title="The Second Term"></a>The Second Term</h3><p>We can see that<br><span>$$\inf_c E || c X - \theta ||^2 = \frac{m \sigma^2 ||\theta||^2}{||\theta||^2 + m \sigma^2}$$</span><!-- Has MathJax --></p>
<p>by optimizing $c$ to get $inf$. </p>
<p>First, consider the bias-variance decomposition for squared loss:</p>
<span>$$E || cX - \theta ||^2 = (c-1)^2 ||\theta||^2 + c^2 m \sigma^2$$</span><!-- Has MathJax -->
<p>By taking the derivative w.r.t. $c$ and setting it equal to zero, we have</p>
<span>$$2(c-1) ||\theta||^2 + 2cm\sigma^2 = 0 \\
c = \frac{||\theta||^2}{||\theta||^2 + m \sigma^2}$$</span><!-- Has MathJax -->
<p>By plugging this value into  $E||cX - \theta||^2$, we have</p>
<span>$$(c-1)^2 ||\theta||^2 + c^2 m \sigma^2 = (\frac{-m\sigma^2}{||\theta||^2 + m \sigma^2})^2 ||\theta||^2 + (\frac{||\theta||^2}{||\theta||^2 + m \sigma^2})^2 m \sigma^2 \\
= \frac{m \sigma^2 ||\theta||^2 }{||\theta||^2 + m \sigma^2 }$$</span><!-- Has MathJax --> 
<p>By combining the results from First Term and Second Term, we have</p>
<span>$$E || \hat{\theta}_{JS} - \theta ||^2 - \inf_c E || c X - \theta ||^2 \le 2 \sigma^2$$</span><!-- Has MathJax --> 
<p>which shows that the risk difference is bounded by $2 \sigma^2$, a constant that doesn’t depend on $c$. </p>
<h2 id="Shrinkage-Estimator"><a href="#Shrinkage-Estimator" class="headerlink" title="Shrinkage Estimator"></a>Shrinkage Estimator</h2><p>Now let’s go back to our original problem of constructing an estimation procedure that achieves </p>
<span>$$E || \hat{\theta} - \theta ||^2 \asymp M^\frac{1}{1+2 \alpha} n^{- \frac{2 \alpha}{2 \alpha+1}}$$</span><!-- Has MathJax --> 
<p>By leveraging the idea of James-Stein estimator, we can think of a form of shrinkage estimator for this problem as well.<br>However, simply using $\hat{\theta} = \hat{\theta}_{JS}$ doesn’t work, because JS implicitely assumes that $\theta_i$ ($i=1,…,m$) are all in the same magnitude, which means that when some $\theta_i$ is big and others are small, the performance will be really bad.<br>This makes sense because we equally shrink $X$ by the same factor: $(1 - \frac{c}{||X||^2})$</p>
<p>The natural extention of the JS procedure is to divide the observation into many blocks and apply a different shrinkcage factor for each block, according to its magnitude. (WLOG, we can assume our observations are sorted in a decreasing order.)</p>
<h2 id="Risk-Calculation"><a href="#Risk-Calculation" class="headerlink" title="Risk Calculation"></a>Risk Calculation</h2><p>The modified JS-like estimation procedure leads us to the following risk:</p>
<span>$$E || \hat{\theta} - \theta ||^2 = E \sum_{i=1}^n (\hat{\theta}_i - \theta_i)^2 + \sum_{i=n+1}^{\infty} \theta_i^2  \\

\le \sum_{k=1}^K \left[ \frac{|B_k| \frac{1}{n} ||\theta_{B_k}||^2}{|B_k|\frac{1}{n}+||\theta_{B_k}||^2} + 2 \frac{1}{n} \right] + O(n^{-\frac{2\alpha}{2\alpha+1}})$$</span><!-- Has MathJax --> 
<p>where $K$ is the number of blocks, $B_k$ represents the $k$ th block, $|B_k|$ is the size of that block.<br>We can naively set the number of elements in each block to be the power of 2, which allows us to write $K = \log_2 n$, where $n$ is the number of observations in total. </p>
<p>The correspondence from the James-Stein estimator risk upper bound is: </p>
<span>$$\sigma^2 = \frac{1}{n}, ||\theta||^2 = ||\theta_{B_k}||^2, m = |B_k|$$</span><!-- Has MathJax -->
<p>Recall that we introduced the threshold index $I$ by considering bias-variance trade-off.<br>This time, we will try to find $K_0$ (the number of blocks) such that $I \le |B<em>1| + \cdots |B</em>{K_0}| \le 2I$ holds. </p>
<p>Now observe that for any positive real number $a$ and $b$, we have $\frac{ab}{a+b} \le a$ and $\frac{ab}{a+b} \le b$.<br>Therefore,</p>
<span>$$\sum_{k=1}^K \left[ \frac{|B_k| \frac{1}{n} ||\theta_{B_k}||^2}{|B_k|\frac{1}{n}+||\theta_{B_k}||^2} + 2 \frac{1}{n} \right] + O(n^{-\frac{2\alpha}{2\alpha+1}}) \\
\le \sum_{k=1}^{K_0} |B_k|\frac{1}{n} + \sum_{k=K_0+1}^K ||\theta_{B_k}||^2 + 2 \frac{1}{n} K + O(n^{-\frac{2 \alpha}{2\alpha+1}}) \\
\le \frac{1}{n} 2I + \sum_{i &gt; I}^{\infty} \theta_i^2 + + O(n^{-\frac{2 \alpha}{2\alpha+1}}) \\$$</span><!-- Has MathJax -->
<p>From the calculation in the last post, we see that this will be upper bounded by</p>
<span>$$\le c M^{\frac{1}{1+2\alpha}} n^{-\frac{2\alpha}{2\alpha+1}}$$</span><!-- Has MathJax -->
<p>One criticism toward this procedure is that the constant $c$ could be huge.<br>Is there a way to reduce it? We will explore alternative blockwise procedure next time.</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-13T00:56:57.000Z"><a href="/blog/2017/03/12/nonparametric-estimation/">2017-03-12</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/12/nonparametric-estimation/">Nonparametric Regression 01</a></h1>
  

    </header>
    <div class="entry">
      
        <p>The goal of this post is to show an instance of derivation of risk bound for nonparmetric regression.   </p>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>For simplicity, we will focus on Gaussian sequence models. That is, our model of interest is the following type:</p>
<span>$$Y_i = \theta_i + \frac{1}{\sqrt{n}} \sigma Z_i, \text{ where } Z_i \sim^{iid} N(0,1)$$</span><!-- Has MathJax -->
<p>for $i = 1, …, n$, where we assume $\sigma=1$. In another word, we observe a noisy parameter $Y$, and we are interested in denoising $Y$ to get the true parameter $\theta$. </p>
<h2 id="Parameter-space"><a href="#Parameter-space" class="headerlink" title="Parameter space"></a>Parameter space</h2><p>Our parameter space is a type of Sobolev ellipsoid:<br><span>$$\Theta = \{ \theta : \sum_{i=1}^{\infty} i^{2 \alpha} \theta^2_i \le M \}$$</span><!-- Has MathJax --> </p>
<p>This way of choose our parameter space implicitly imposes smoothness assumption on function space we might be interested in. For example, if we view our estimation problem as a function estimation, the problem becomes to estimate a function $f(x)$ through a set of discrete sample pairs $(X_i, Y_i)$.<br>By Fourier basis expansion, </p>
<span>$$f(x) = \sum_{i=1}^{\infty} &lt;f, \varphi_i&gt; \varphi_i(x) \\
= \sum_{i=1}^{\infty} \theta_i \varphi_i(x)$$</span><!-- Has MathJax -->
<p>where <span>$\theta_i =  &lt;f, \varphi_i&gt;$</span><!-- Has MathJax --> and</p>
<span>$$\varphi_i(x) = 
\begin{cases} 
    cos(cix) \\
    sin(cix)
\end{cases}$$</span><!-- Has MathJax -->
<p>Imposing smoothness assumption on $f$ by bounding the integral of $f$’s second derivative is equivalent to the condition in our parameter space. That is, </p>
<span>$$f&apos;&apos;(x) = \sum_{i=1}^{\infty} \theta_i (\varphi_i(x))&apos;&apos; \\
= \sum_{i=1}^{\infty} \theta_i (ci)^2 \varphi_i(x)$$</span><!-- Has MathJax -->  
<p>So</p>
<span>$$\int (f&apos;&apos;(x))^2 dx \le M&apos; \iff \sum_{i=1}^{\infty} [\theta_i (ci)^2]^2 \le M&apos; \\
\sum_{i=1}^{\infty} c^4 i^4 \theta_i^2 \le M&apos;$$</span><!-- Has MathJax -->
<p>(In this derivation, we’ve assumed $\alpha=2$.)</p>
<p>Note that without any parameter space condition, the best estimation procedure is the linear procedure. We can show this through Pinsker bound, which we might go over in the future posts under decision-theory tag. </p>
<h2 id="Goal-of-inference-problem"><a href="#Goal-of-inference-problem" class="headerlink" title="Goal of inference problem"></a>Goal of inference problem</h2><p>Estimate $\theta$. Our loss function is </p>
<span>$$|| \hat{\theta} - \theta ||^2 = \sum_{i=1}^{\infty} (\hat{\theta}_i - \theta_i)^2$$</span><!-- Has MathJax -->
<h2 id="Estimation-Procedure"><a href="#Estimation-Procedure" class="headerlink" title="Estimation Procedure"></a>Estimation Procedure</h2><p>Intuitively, due to our parameter space restriction, when $i$ is large, $\theta_i$ has to become smaller, and at some point or later, it becomes neglible. This observation leads to the following naive estimator:</p>
<span>$$\hat{\theta}_i =  
\begin{cases} 
        Y_i &amp; i \le I  \\
        0    &amp; i &gt; I 
\end{cases}$$</span><!-- Has MathJax --> 
<p>where $I$ is the threshold value we will optimize (in terms of having a tigher risk lower bound) soon. </p>
<h2 id="Risk-Calculation"><a href="#Risk-Calculation" class="headerlink" title="Risk Calculation"></a>Risk Calculation</h2><p>With this procedure, we can easily calculate risk for each case. That is, when $\hat{\theta}_i = Y_i$, its risk is $E (Y_i - \theta_i)^2 = \frac{1}{n}$ (Note: this is just the variance of $Y_i$, which is $\frac{1}{n}$ from the definition of our model.) When $\hat{\theta}_i = 0$, its risk is $E (0 - \theta_i)^2 = \theta_i^2$ (Note that expectation is taken over data, and $\theta$ is deterministic value.) </p>
<p>With this simple algebra above, we observe that if $\theta^2_i \le \frac{1}{n}$, we want to use $\hat{\theta}_i = 0$, which is imposed by $i &gt; I$ condition. </p>
<p>The risk of this procedure is given by</p>
<span>$$R(\hat{\theta}) = E \sum_{i=1}^{\infty} (\hat{\theta}_i - \theta)^2 = E \sum_{i=1}^I (Y_i - \theta_i)^2 + E \sum_{i=I+1}^{\infty} \theta^2_i$$</span><!-- Has MathJax --> 
<h2 id="Risk-upper-bound"><a href="#Risk-upper-bound" class="headerlink" title="Risk upper bound"></a>Risk upper bound</h2><p>We immediately see that the first term is equivalent to $\frac{I}{n}$.<br>The question is how to upper bound the second term.<br>Recall the condition of our parameter space definition: $\sum_{i=0}^{\infty} i^{2 \alpha} \theta_i^2  \le M$. From this, we observe the following inequalities:</p>
<span>$$\sum_{i=0}^{\infty} i^{2 \alpha} \theta_i^2 \le M \\ 
\Rightarrow  \sum_{i = I + 1}^{\infty} i^{2 \alpha} \theta_i^2 \le M  \\ 
\Rightarrow (I+1)^{2\alpha} \sum_{i = I + 1}^{\infty} \theta_i^2 \le M \\ 
\Rightarrow \sum_{i = I + 1}^{\infty} \theta_i^2 \le \frac{M}{(I+1)^{2\alpha}} \le \frac{M}{I^{2 \alpha}}$$</span><!-- Has MathJax --> 
<p>So our upper bound is</p>
<span>$$R(\hat{\theta}) \le  \frac{I}{n} + \frac{M}{I^{2 \alpha}}$$</span><!-- Has MathJax --> 
<p>To find an optimal $I$, we will treat $\frac{M}{I^{2 \alpha}}$ as $Bias^2$, and pick $I$ to achieve the optimal variance-bias tradeoff. This leads to </p>
<span>$$\frac{I}{n} = \frac{M}{I^{2 \alpha}} \iff I^{1+2\alpha} = Mn \iff I = (Mn)^{\frac{1}{1+2\alpha}}$$</span><!-- Has MathJax --> 
<p>Therefore, </p>
<span>$$R(\hat{\theta}) \le \frac{I}{n} + \frac{M}{I^{2 \alpha}} = \frac{2}{n} (Mn)^{\frac{1}{1+2\alpha}} = 2 M^{\frac{1}{1+2\alpha}} n^{-\frac{2\alpha}{1+2\alpha}}$$</span><!-- Has MathJax --> 
<p>This leads to our risk upper bound:</p>
<span>$$sup_{\Theta} E || \hat{\theta} - \theta ||^2 \le  2 M^{\frac{1}{1+2\alpha}} n^{-\frac{2\alpha}{1+2\alpha}}$$</span><!-- Has MathJax --> 
<p>(We will try to find a better rate in some later posts.)</p>
<h2 id="Risk-lower-bound"><a href="#Risk-lower-bound" class="headerlink" title="Risk lower bound"></a>Risk lower bound</h2><p>To find lower bound, we resort to Le Cum’s idea. </p>
<p>We first construct a sub-parameter space so that the resulting risk calculation over the sub-parameter space is simple enough. Considering a sub-parameter space is useful because for any sub-parameter space $\Theta_0 \subset \Theta$, we have the following lower bound for sup risk for $\Theta$. </p>
<span>$$sup_{\Theta} E || \hat{\theta} - \theta||^2 \ge sup_{\Theta_0} E || \hat{\theta} - \theta ||^2$$</span><!-- Has MathJax --> 
<p>In our case, let our sub-parameter space be</p>
<span>$$\Theta_0 = \{ \theta : \theta_i = 0 \text{ if } i \ge I + 1, \theta_i = \frac{1}{\sqrt{n}} \text{ if } i \le I \}$$</span><!-- Has MathJax -->
<p>where $I$ is the previous optimal value : $I = (Mn)^{\frac{1}{1+2\alpha}}$. </p>
<p>We can confirm that <span>$\Theta_0$</span><!-- Has MathJax --> is indeed in <span>$\Theta$</span><!-- Has MathJax -->  by checking the condition <span>$\sum_{i=1}^{\infty} i^{2\alpha} \theta_i^2 \le M$</span><!-- Has MathJax -->: </p>
<span>$$\sum_{i=1}^I i^{2 \alpha} \frac{1}{n} = \frac{1}{n} \sum_{i=1}^I i^{2\alpha} \le \frac{1}{n} I I^{2\alpha} = \frac{1}{n} Mn = M$$</span><!-- Has MathJax --> 
<p>Now, we want to lower bound <span>$sup_{\Theta_0} E || \hat{\theta} - \theta ||^2$</span><!-- Has MathJax -->: </p>
<span>$$sup_{\Theta_0} E || \hat{\theta} - \theta ||^2 \ge  sup_{\Theta_0} E \sum_{i=1}^I \hat{\theta} - \theta ||^2  \\$$</span><!-- Has MathJax -->
<p>Now assume a prior on $\theta_i$ such that</p>
<span>$$\theta_i =
\begin{cases}
    0 &amp; \text{ w.p. } \frac{1}{2} \\
    \frac{1}{\sqrt{n}} &amp;  \text{ w.p. } \frac{1}{2} 
\end{cases}$$</span><!-- Has MathJax --> 
<p>Then, by observing that $sup_x f(x) \ge E_x f(x)$, we have </p>
<span>$$sup_{\Theta_0} E \sum_{i=1}^I || \hat{\theta} - \theta ||^2  \ge E_{\theta} E_{Y|\theta} [ \sum_{i=1}^I (\hat{\theta}_i - \theta_i )^2 ]$$</span><!-- Has MathJax -->
<p>Now recall that Bayes estimator is supposed to attain the smallest risk. This gives us the following further lower bound:</p>
<span>$$E_{\theta} E_{Y|\theta} [ \sum_{i=1}^I (\hat{\theta}_i - \theta_i )^2 ] \ge E_{\theta} E_{Y|\theta} [ \sum_{i=1}^I (\hat{\theta}_{i,Bayes} - \theta_i )^2 ]$$</span><!-- Has MathJax --> 
<p>Note that <span>$\hat{\theta}_{i,Bayes}$</span><!-- Has MathJax --> is a function of $Y_i$ only due to $i.i.d$ assumption. Therefore using our definition of prior,</p>
<span>$$E_{\theta} E_{Y|\theta} [ \sum_{i=1}^I (\hat{\theta}_{i,Bayes} - \theta_i )^2 ] 
= \sum_{i=1}^I [ \frac{1}{2} E_{Y_i|\theta_i=0} (\hat{\theta}_{i,Bayes} - 0)^2 + \frac{1}{2} E_{Y_i|\theta_i=\frac{1}{\sqrt{n}}} (\hat{\theta}_{i,Bayes} - \frac{1}{\sqrt{n}})^2 ]$$</span><!-- Has MathJax --> 
<p>Rewriting the above equation with $\phi_{a,b}(x)$ be the pdf of N(a,b) yields</p>
<span>$$\sum_{i=1}^I [ \frac{1}{2} E_{Y_i|\theta_i=0} (\hat{\theta}_{i,Bayes} - 0)^2 + \frac{1}{2} E_{Y_i|    \theta_i=\frac{1}{\sqrt{n}}} (\hat{\theta}_{i,Bayes} - \frac{1}{\sqrt{n}})^2  \\
= \sum_{i=1}^I \frac{1}{2} [ \int (\hat{\theta}_{i,Bayes} - 0)^2 \phi_{0,\frac{1}{n}}(x)dx + \int (\hat{\theta}_{i,Bayes} - \frac{1}{\sqrt{n}})^2  \phi_{\frac{1}{\sqrt{n}},\frac{1}{n}}(x) dx ]$$</span><!-- Has MathJax --> 
<p>Let <span>$g(x) = \min \{ \phi_{0,\frac{1}{n}}(x), \phi_{\frac{1}{\sqrt{n}},\frac{1}{n}}(x) \}$</span><!-- Has MathJax -->. Then using $g(x)$, the above equation can be lower bounded:</p>
<span>$$\ge \sum_{i=1}^I \frac{1}{2} \int \left( ( \hat{\theta}_{i,Bayes} - 0)^2 + (\hat{\theta}_{i,Bayes} - \frac{1}{\sqrt{n}})^2 \right)  g(x) dx$$</span><!-- Has MathJax -->
<p>Observing that <span>$a^2 + b^2 \ge \frac{1}{2} (a-b)^2$</span><!-- Has MathJax -->, we can rewrite it to</p>
<span>$$\ge \sum_{i=1}^I \frac{1}{2} \int \frac{1}{2} (\frac{1}{\sqrt{n}})^2 g(x) dx = \frac{I}{n} \frac{1}{4} \int g(x) dx$$</span><!-- Has MathJax -->
<p>Since $\int g(x) dx$ is some constant $c$, our risk lower bound is</p>
<span>$$c \frac{I}{n} = c n^{- \frac{2 \alpha}{2 \alpha + 1}}$$</span><!-- Has MathJax --> 
<p>This establishes our risk lower bound for this particular estimation procedure under this model. </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-10T06:08:10.000Z"><a href="/blog/2017/03/10/notes-on-priors/">2017-03-10</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/03/10/notes-on-priors/">Notes on priors</a></h1>
  

    </header>
    <div class="entry">
      
        <p>A requirement </p>
<h2 id="The-Jeffreys-prior"><a href="#The-Jeffreys-prior" class="headerlink" title="The Jeffreys prior"></a>The Jeffreys prior</h2><ul>
<li>invariant under transformation. </li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-03T20:37:20.000Z"><a href="/blog/2017/02/03/mcmc/">2017-02-03</a></time>
      
      
  
    <h1 class="title"><a href="/blog/2017/02/03/mcmc/">Notes on MCMC</a></h1>
  

    </header>
    <div class="entry">
      
        <p>MCMC (Markov Chain Monte Carlo) is a way to numerically sample from posterior distribution of interest by constructing Markov Chain in a smart way so that the stationary distribution of MC matches the desired posterior distribution.</p>
<p>The way I see it is to consider Markov Chain as a search on the parameter space. The goal is to find a parameter $\theta$ that specifies the desired posterior distribution $p(\theta|x)$. </p>
<p>To have a concrete picture, it’s useful to consider the parameter space (or should I say distribution space, which emphasizes that the space is invariance to reparametrization?) as a discrete space. </p>
<p>Let’s say we partition the parameter space into a countable blocks, and we start from a certain block at time 0.<br>Suppose at time $t$, we are at block $x$. Denote this probability as $P(\theta_t \in x)$ </p>
<p>How should we move? </p>
<ul>
<li><p>we should move toward regions of the parameter space with higher probability (with respect to the target distribution? But we don’t know this distribution do we..? Oh but we do know the likelihood and prior. So, although we cannot calculate the posterior distribution exactly, we are able to evaluate if the current point is higher than the next point, because this evaluation can be done by $\frac{p(\theta<em>{t+1})p(x|\theta</em>{t+1})}{p(\theta<em>{t})p(x|\theta</em>{t})}$; the integral constant will be cancelled out when you take the proportion.)</p>
</li>
<li><p>we should avoid the regions with lower probability with respect to the target distribution. </p>
</li>
</ul>
<p>Transition matrix T(x|y) $\iff$ Proposal distribution with pdf $g(x|x’)$ defined for all $x,x’ \in \xx$. </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><p><a href="http://astrostatistics.psu.edu/su14/lectures/CosPop14-2-2-BayesComp-2.pdf" target="_blank" rel="external">http://astrostatistics.psu.edu/su14/lectures/CosPop14-2-2-BayesComp-2.pdf</a></p>
</li>
<li><p><a href="http://www2.stat.duke.edu/~km68/materials/214.7%20(MH).pdf" target="_blank" rel="external">http://www2.stat.duke.edu/~km68/materials/214.7%20(MH).pdf</a></p>
</li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
    <a href="/blog/page/2/" class="alignright next">Nächste Seite</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="q" value="site:runopti.github.io/blog">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/blog/tags/PRML/">PRML</a><small>1</small></li>
  
    <li><a href="/blog/tags/cv/">cv</a><small>1</small></li>
  
    <li><a href="/blog/tags/decision-theory/">decision-theory</a><small>3</small></li>
  
    <li><a href="/blog/tags/learning-theory/">learning-theory</a><small>2</small></li>
  
    <li><a href="/blog/tags/math/">math</a><small>7</small></li>
  
    <li><a href="/blog/tags/neuralnet/">neuralnet</a><small>9</small></li>
  
    <li><a href="/blog/tags/optimization/">optimization</a><small>5</small></li>
  
    <li><a href="/blog/tags/paper-memo/">paper-memo</a><small>2</small></li>
  
    <li><a href="/blog/tags/research/">research</a><small>0</small></li>
  
    <li><a href="/blog/tags/variational-inference/">variational-inference</a><small>2</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 Yutaro Yamada
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>




<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]],"processEscapes":true}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
